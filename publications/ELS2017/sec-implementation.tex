% -*- TeX-master: "petalisp.tex"; TeX-engine: xetex; coding: utf-8 -*-
\section{Implementation}
\label{sec:implementation}

The Petalisp language is a pragmatic approach to parallel programming. Its
goal is not primarily to advance the theoretical understanding of
parallelism, but to derive a practical solution for modern scientific
computing. The development and maintenance of a high-quality Petalisp
implementation is a crucial step towards this goal.

Throughout the implementation, we faced two exciting challenges. On the one
hand, Petalisp must be fast enough to be competitive with existing software
in High-Performance Computing. On the other hand, since Petalisp is
university project, it must be simple enough that new developers can read
and understand the full source code within a few days.

\subsection{Evaluation of Petalisp Programs}

Petalisp programs themselves are not meaningful. There is (deliberately) no
way to access the contents of a strided array. The only way to do so is to
convert the result of a Petalisp program back to a Lisp array or scalar. An
advantage of this strategy is that the execution of the whole Petalisp
program can be delayed until such a conversion is requested. The result is
unprecedented potential for optimization, albeit with the price that all
compilation has to be performed just-in-time.

For some applications, it is desirable to compute multiple strided arrays,
but convert only some of them to Lisp objects, e.g. to check some control
parameters and pass the remaining arguments to another Petalisp program. To
accommodate this case, the evaluation of Petalisp programs is split into
two functions: \emph{compute} and \emph{petalisp->lisp}:

\begin{function}
  \texttt{ \textbf{compute} \&rest arguments} & \textsl{function} \\
\end{function}

Force the evaluation of all \texttt{arguments}. Returns as many values as
there have been arguments. All result values are of type
\texttt{strided-array}.

\begin{function}
  \texttt{ \textbf{petalisp->lisp} argument} & \textsl{function} \\
\end{function}

If \texttt{argument} has not been evaluated yet, do so. Afterwards, if it
is a strided array of dimension zero, convert it to a Lisp scalar. If it is
a strided array of higher dimension, translate it to an origin of zero,
scale it to a step size of one and convert it to a Lisp array.

\subsection{Data Flow Graph Optimization}

Each strided array is also an instance of one of the classes
\emph{constant}, \emph{application}, \emph{reduction}, \emph{fusion} or
\emph{reference}. All instances except constants track their predecessors
in the data flow graph. Therefore and because of lazy evaluation, a strided
array is more a recipe than a data structure. Figure \ref{fig:matmul-graph}
shows the data flow graph for an invocation of the matrix multiplication
program in figure \ref{fig:matmul} with a $1\times 2$ matrix A and a
$2 \times 5$ matrix B.

\begin{figure}[htb]
\begin{center}
  \begin{tikzpicture}
    [petanode/.style={
      rectangle,
      rounded corners = 3mm,
      minimum size=12mm,
      thick,draw=black,
      font=\ttfamily},
    arrow/.style={<-,shorten <=1pt,thick},
    align=center]
    \node (lconst)      [petanode] at (1,6) {constant\\(σ (1 3) (1 2))};
    \node (rconst)      [petanode] at (5,6) {constant\\(σ (1 2) (1 5))};
    \node (lrepetition) [petanode] at (1,4) {reference\\(τ (A B C) A C)\\(σ (1 3) (1 5) (1 2))}
     edge [arrow] (lconst);
    \node (rrepetition) [petanode] at (5,4) {reference\\(τ (A B C) C B)\\(σ (1 3) (1 5) (1 2))}
     edge [arrow] (rconst);
    \node (application) [petanode] at (3,2) {application (*)\\(σ (1 3) (1 5) (1 2))}
     edge [arrow] (lrepetition)
     edge [arrow] (rrepetition);
    \node (reduction)   [petanode] at (3,0) {reduction (+)\\(σ (1 3) (1 5))}
     edge [arrow] (application);
\end{tikzpicture}
\end{center}
\caption{The data flow graph of a matrix multiplication}
\label{fig:matmul-graph}
\end{figure}

There is a lot of potential for optimization during graph
creation. Multiple consecutive references can be combined to a single one
by forming the functional composition of their transformations. Operations
on small, constant arrays can be evaluated immediately, producing a new
constant. References to a fusion can directly reference the relevant inputs
of that fusion. These transformations are the first place where the
simplicity of the core language pays off. It is sufficient to consider all
interactions between four different operators.

To exploit the aforementioned simplifications as soon as possible, they are
performed directly within the core operators. Each core operator, e.g.
\emph{application} is a generic function that constructs a new data flow
graph node by default. Specialized functions override this behavior to
simplify or avoid this node construction where possible. A result of these
early transformations is that the data flow graph of a Petalisp program is
often much shorter than its generating source code, e.g. an invocation of
the code in figure \ref{fig:references} is completely optimized away.

\begin{figure}[htb]
\resetlinenumber
\begin{code}
(defun useless-references (x)
  (setf x (-> x (τ (x) (+  1 x))))
  (setf x (-> x (τ (x) (+  9 x))))
  (setf x (-> x (τ (x) (- 10 x)))))
\end{code}
\caption{Three consecutive translating references.}
\label{fig:references}
\end{figure}

\subsection{Code Generation}

Once the data flow graphs have been assembled and simplified, they are
evaluated. This evaluation consists of the following steps:

\begin{enumerate}
\item \textbf{grouping into kernels}\, As many nodes as possible are
  grouped to a single kernel. Kernel boundaries occur e.g. when one value
  is required from multiple sources. The matrix multiplication graph in
  figure \ref{fig:matmul-graph} would be grouped into a single kernel.

\item \textbf{kernel analysis}\, Each kernel is analyzed to approximate its
  computational cost and some auxiliary metrics.

\item \textbf{scheduling and allocation}\, The previously gathered
  information is used to derive a reasonable scheduling strategy and to map
  the value of each kernel to a memory location\footnote{This phase is similar to
  register allocation in classical compilers.}.
\item \textbf{execution}\, Communications and computations are performed
  according to the schedule. During communication, data is exchanged to
  ensure that all necessary information for a kernel invocation is locally
  available. During computation, a kernel is used as a blueprint to
  generate and compile specialized source code for this particular
  problem. Afterwards, this code is applied to the given input and output
  memory locations to compute the next value.
\end{enumerate}

The code generator is still under development, but nonetheless fully
functional. While it seems expensive to compile each kernel at runtime,
this cost is greatly diminished by caching all compiled kernels for future
use. Except for some pathological programs, compilation quickly becomes as
cheap as a single hash table lookup.
